{
    "name": "llama-cpp-openai-api",
    "version": "1.0.0",
    "description": "Use llama.cpp in place of the OpenAi API.",
    "main": "index.js",
    "type": "module",
    "scripts": {
        "start": "node index.js",
        "dev": "nodemon index.js",
        "client": "cd client && npm start",
        "server": "npm start",
        "build": "cd client && npm run build",
        "postinstall": "cd client && npm install && npm run build"
    },
    "author": "",
    "license": "ISC",
    "dependencies": {
        "child_process": "^1.0.2",
        "cors": "^2.8.5",
        "express": "^4.18.2",
        "fs": "^0.0.1-security",
        "nanoid": "^4.0.2",
        "path": "^0.12.7",
        "swagger-jsdoc": "^6.2.8",
        "swagger-ui-express": "^4.6.2"
    },
    "devDependencies": {
        "nodemon": "^2.0.22"
    },
    "proxy": "http://localhost:5000"
}
